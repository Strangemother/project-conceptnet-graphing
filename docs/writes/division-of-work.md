# Conceptual Division

[Concept] 30/06/2018

The curret space addressing doesn't function accurately. The strictly procedural
inspection through a number of graphs doesn't populate a _concept_ in an easy-to-address object.

This leads to nesting meta data in logical objects - leading to a poor taxonomy. With this a change to the meta graphing and how sparse graphs can communicate

Current:

    Input => Assess String => Inital context graphing => secondary graphing => Memory => LTS

The init context graphing manages cross-referencing of other immediate concepts, and the secondary graphing assigns deeper meaning and recursive corrections. The graph context exists within object data and extracted through each process.


Instead the division of labour is performed at the initial graph stage whilst maintaining a temporal space for a given sentence. Therefore additional context is applied asyncronously.


We can define elements of intent through purpose graphs, perhaps hard-coded. The additional context graphing units we can call a "module". A single module will provide a sub-graph to apply additional context to the originator. The sentence list (temporal string registry within the immediate context graph) manages a set of quickly changing associations - weighted and managed by another graph and ML trained weighting machine.


To simplify; A sentence "I like the month of may" is assessed as a temporal string. A module will exist for _operator self reference_, _emotive awareness_ and date extraction. The conceptual graphs for "I" and "Like" may require emotive knowledge and literal translation before use. A module reacts to the newly requested graphing and responds with a unique ID and result.
The additional meta result will include a weighting number for the sentence cross-reference transient weight value.

When a sentence is altered, its current graphs and cross-referencing should be re-evalutated applying the new weights from the module. As each _word_ of a sentence could change at any time, a _reasoning module_ should decide if newly weighted graph is better than the current immediate context.

I feel this may yield a lot of mistakes initially, but a 3rd ML layer for attaining a record of corrections - should apply the previously taught correcting within the "literal translate" stage (effectivly hot-wiring the reasoning module extraction to previously canned results).

